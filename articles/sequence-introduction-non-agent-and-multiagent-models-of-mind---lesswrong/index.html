<!DOCTYPE html>
<html><meta charset="utf-8"><link href="/index.css" rel="stylesheet"><title>@meekaale [[articles]] Sequence Introduction: Non-Agent and Multiagent Models of Mind - LessWrong</title><header><a href="/">@meekaale</a>Â Â»Â <a href="/articles/">Articles</a>Â Â»Â <strong><a class="ref" href="/articles">ðŸ“°</a> Sequence Introduction: Non-Agent and Multiagent Models of Mind - LessWrong</strong></header><article><section><h1><a class="ref" href="/articles">ðŸ“°</a> Sequence Introduction: Non-Agent and Multiagent Models of Mind - LessWrong</h1><p><strong>Author</strong>: <a class="ref" href="/topics/lesswrong-dot-com">lesswrong.com</a></p><div class="indent"></div><p><strong>Full Title</strong>: Sequence Introduction: Non-Agent and Multiagent Models of Mind - LessWrong</p><div class="indent"></div><p><strong>URL</strong>: <a href="https://www.lesswrong.com/posts/M4w2rdYgCKctbADMn/sequence-introduction-non-agent-and-multiagent-models-of">https://www.lesswrong.com/posts/M4w2rdYgCKctbADMn/sequence-introduction-non-agent-and-multiagent-models-of</a></p><div class="indent"></div><h3>Highlights from <a class="ref" href="/days/march-5th-2021">March 5th, 2021</a>.</h3><div class="indent"><blockquote>I would go as far as to claim that this is the biggest flaw of the original Sequences: they were attempting to explain many failures of rationality as being due to cognitive biases, when in retrospect it looks like understanding cognitive biases doesnâ€™t actually make you substantially more effective. But if you are implicitly modeling humans as goal-directed agents, then cognitive biases is the most natural place for irrationality to emerge from, so it makes sense to focus the most on there.</blockquote><div class="indent"></div></div></section></article></html>