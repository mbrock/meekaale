<!DOCTYPE html>
<html><meta charset="utf-8"><meta content="width=device-width, initial-scale=1" name="viewport"><link href="/index.css" rel="stylesheet"><meta content="summary" name="twitter:card"><meta content="@meekaale" name="twitter:site"><meta content="[[articles]] The Case Against Reality" name="twitter:title"><meta content="@meekaale&apos;s highlights from [[articles]] The Case Against Reality" name="twitter:description"><title>[[articles]] The Case Against Reality - @meekaale</title><header><a href="/">@meekaale</a>Â Â»Â <a href="/articles/">Articles</a>Â Â»Â <a class="ref" href="/articles">ğŸ“°</a> The Case Against Reality</header><article><section><h2><a class="ref" href="/articles">ğŸ“°</a> The Case Against Reality</h2><p><strong>Author</strong>: <a class="ref" href="/topics/amanda-gefter">Amanda Gefter</a></p><p><strong>Full Title</strong>: The Case Against Reality</p><p><strong>URL</strong>: <a href="https://www.theatlantic.com/science/archive/2016/04/the-illusion-of-reality/479559/">https://www.theatlantic.com/science/archive/2016/04/the-illusion-of-reality/479559/</a></p><h3>Highlights from <a class="ref" href="/days/2021-03-08">March 8th, 2021</a>.</h3><div class="indent"><blockquote>Hoffman has spent the past three decades studying perception, artificial intelligence, evolutionary game theory and the brain, and his conclusion is a dramatic one: The world presented to us by our perceptions is nothing like reality. Whatâ€™s more, he says, we have evolution itself to thank for this magnificent illusion, as it maximizes evolutionary fitness by driving truth to extinction.</blockquote><blockquote>The classic argument is that those of our ancestors who saw more accurately had a competitive advantage over those who saw less accurately and thus were more likely to pass on their genes that coded for those more accurate perceptions, so after thousands of generations we can be quite confident that weâ€™re the offspring of those who saw accurately, and so we see accurately. That sounds very plausible. But I think it is utterly false.</blockquote><blockquote>The mathematical physicist Chetan Prakash proved a theorem that I devised that says: According to evolution by natural selection, an organism that sees reality as it is will never be more fit than an organism of equal complexity that sees none of reality but is just tuned to fitness.</blockquote><blockquote>Suppose in reality thereâ€™s a resource, like water, and you can quantify how much of it there is in an objective orderâ€”very little water, medium amount of water, a lot of water. Now suppose your fitness function is linear, so a little water gives you a little fitness, medium water gives you medium fitness, and lots of water gives you lots of fitnessâ€”in that case, the organism that sees the truth about the water in the world can win, but only because the fitness function happens to align with the true structure in reality. Generically, in the real world, that will never be the case.</blockquote><blockquote>You could not form a true description of the innards of the computer if your entire view of reality was confined to the desktop. And yet the desktop is useful.</blockquote><blockquote>Evolution has shaped us with perceptions that allow us to survive. They guide adaptive behaviors. But part of that involves hiding from us the stuff we donâ€™t need to know. And thatâ€™s pretty much all of reality, whatever reality might be</blockquote><blockquote>Snakes and trains, like the particles of physics, have no objective, observer-independent features. The snake I see is a description created by my sensory system to inform me of the fitness consequences of my actions.</blockquote><blockquote>I have a space X of experiences, a space G of actions, and an algorithm D that lets me choose a new action given my experiences. Then I posited a W for a world, which is also a probability space. Somehow the world affects my perceptions, so thereâ€™s a perception map P from the world to my experiences, and when I act, I change the world, so thereâ€™s a map A from the space of actions to the world. Thatâ€™s the entire structure. Six elements. The claim is: This is the structure of consciousness. I put that out there so people have something to shoot at.</blockquote><blockquote>Hereâ€™s the striking thing about that. I can pull the W out of the model and stick a conscious agent in its place and get a circuit of conscious agents. In fact, you can have whole networks of arbitrary complexity. And thatâ€™s the world.</blockquote><blockquote>I call it conscious realism: Objective reality is just conscious agents, just points of view.</blockquote><blockquote>Interestingly, I can take two conscious agents and have them interact, and the mathematical structure of that interaction also satisfies the definition of a conscious agent. This mathematics is telling me something. I can take two minds, and they can generate a new, unified single mind.</blockquote><blockquote>We have two hemispheres in our brain. But when you do a split-brain operation, a complete transection of the corpus callosum, you get clear evidence of two separate consciousnesses. Before that slicing happened, it seemed there was a single unified consciousness. So itâ€™s not implausible that there is a single conscious agent. And yet itâ€™s also the case that there are two conscious agents there, and you can see that when theyâ€™re split.</blockquote><blockquote>I didnâ€™t expect that, the mathematics forced me to recognize this. It suggests that I can take separate observers, put them together and create new observers, and keep doing this ad infinitum. Itâ€™s conscious agents all the way down.</blockquote><blockquote>The idea that what weâ€™re doing is measuring publicly accessible objects, the idea that objectivity results from the fact that you and I can measure the same object in the exact same situation and get the same results â€” itâ€™s very clear from quantum mechanics that that idea has to go. Physics tells us that there are no public physical objects.</blockquote><blockquote>The neuroscientists are saying, â€œWe donâ€™t need to invoke those kind of quantum processes, we donâ€™t need quantum wave functions collapsing inside neurons, we can just use classical physics to describe processes in the brain.â€ Iâ€™m emphasizing the larger lesson of quantum mechanics: Neurons, brains, space â€¦ these are just symbols we use, theyâ€™re not real. Itâ€™s not that thereâ€™s a classical brain that does some quantum magic. Itâ€™s that thereâ€™s no brain!</blockquote><blockquote>As a conscious realist, I am postulating conscious experiences as ontological primitives, the most basic ingredients of the world. Iâ€™m claiming that experiences are the real coin of the realm. The experiences of everyday lifeâ€”my real feeling of a headache, my real taste of chocolateâ€”that really is the ultimate nature of reality.</blockquote></div></section></article></html>